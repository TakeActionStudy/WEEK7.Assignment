{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 평균 이동과 K-평균의 차이점을 설명하고 평균 이동의 장점/단점을 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-평균은 중심에 소속된 데이터의 평균 거리 중심으로 이동하지만 평균 이동은 데이터가 모여 있는 밀도가 가장 높은 곳으로 이동.\n",
    "평균 이동 장점: 데이터 세트 형태를 특정 형태, 특정 분포도 기반의 모델로 가정 X -> 좀 더 유연한 군집화 가능, 이상치 영향력 크지 X, 미리 군집의 개수 정할 필요 X\n",
    "평균 이동 단점: 수행 시간이 오래 걸리고, 대역폭의 크기에 따른 군집화 영향도 큼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 평균 이동에서 KDE의 대역폭(h)값에 따른 KDE의 변화와 평균 이동 군집화 개수에 대해 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작은 h(h=1.0): 좁고 뾰족한 KDE를 가짐, 변동성이 큰 방식으로 확률 밀도 함수 추정 -> 과적합하기 쉬움, 많은 군집 중심점을 가짐.\n",
    "큰 h(h=10): 과도하게 평활화된 KDE를 가짐, 지나치게 단순화된 방식으로 확률 밀도 함수 추정 -> 과소적합하기 쉬움, 적은 수의 군집 중심점을 가짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. GMM의 군집화 방식에 대해 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM은 데이터를 여러 개의 정규 분포가 섞인 것으로 간주. 군집화 하려는 데이터 분포에서 개별 정규 분포를 추출하고, 개별 데이터가 어느 정규 분포에 속하는지 결정하는 방식."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. GMM과 K-평균의 차이점에 대해 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-평균은 거리 기반 군집화이므로 데이터 세트가 원형의 범위를 가질수록 군집화 효율 늘어남. But 길쭉한 방향으로 데이터가 밀접해 있을 경우 최적의 군집화 어려움.\n",
    "GMM은 좀 더 유연하게 다양한 데이터 세트에 적용 가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. DBSCAN의 가장 중요한 파라미터 두 개의 대해 설명하고 DBSCAN의 군집화 방식에 대해 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epsilon: 개별 데이터를 중심으로 입실론 반경을 가지는 원형의 영역, 사이킷런 DBSCAN 클래스에서 eps로 표현.\n",
    "min points: 개별 데이터의 입실론 주변 영역에 포함되는 타 데이터 개수, 사이킷런 DBSCAN 클래스에서 min_samples로 표현.\n",
    "입실론 주변 영역 내에 포함되는 최소 데이터 개수의 충족 여부에 따라 데이터 포인트를 핵심 포인트, 이웃 포인트, 경계 포인트, 잡음 포인트로 구분 후 특정 핵심 포인트에서 직접 접근이 가능한 다른 핵심 포인트를 서로 연결하면서 군집화 구성(입실론 주변 영역의 최소 데이터 개수를 포함하는 밀도 기준을 충족시키는 핵심 포인트를 연결하면서 군집화 구성)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 텍스트 전처리 작업들에 대해 설명하시오(ex 클렌징, 토큰화...). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 클렌징: 불필요한 문자, 기호 제거(ex) HTML, XML 태그)\n",
    "2. 텍스트 토큰화: 1) 문장 토큰화: 문장의 마지막을 뜻하는 기호에 따라 분리(ex) 마침표(.), 개행문자(\\n)) \n",
    "2) 단어 토큰화: 공백, 콤마(,), 마침표(.), 개행문자 등으로 단어 분리 \n",
    "3. 스톱 워드 제거: 스톱 워드는 분석에 큰 의미가 없는 단어를 의미(is, the, a, will)\n",
    "4. Stemming, Lemmatization: 문법적 또는 의미적으로 변화하는 단어의 원형을 찾는 것.\n",
    "1) Stemming: 원형 단어 변환시 단순화된 방법을 적용해 원래 단어에서 일부 철자가 훼손된 어근 단어를 추출하는 경향이 있음.\n",
    "2) Lemmatization: 문법적 요소와 의미적 부분을 감안해 어근 단어 추출."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. BOW 피처 벡터화 중 카운트 기반 벡터화와 TF-IDF기반 벡터화의 차이점에 대해 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 카운트 기반 벡터화: 각 문서에 해당 단어가 나타나는 횟수를 count. count값이 높을수록 중요한 단어로 인식. 문서의 특징을 나타내는 것이 아닌 언어 특성상 자주 사용되는 단어까지 높은 값을 부여.\n",
    "2. TF-IDF기반 벡터화: 개별 문서에 자주 나타나는 단어에 가중치를 주고, 모든 문서에서 전반적으로 자주 나타나는 단어에는 패널티를 부여. 텍스트가 길고 문서의 개수가 많은 경우 TF-IDF가 카운트 방식보다 좋은 예측 성능을 가짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 첨부된 데이터를 이용하여 텍스트 분석 실습 하시오.\n",
    "데이터 링크는 다음과 같다.\n",
    "https://www.kaggle.com/seriousran/appletwittersentimenttexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow. Yall needa step it up @Apple RT @heynyla:...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What Happened To Apple Inc?   http://t.co/FJEX...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank u @apple I can now compile all of the pi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  Wow. Yall needa step it up @Apple RT @heynyla:...         -1\n",
       "1  What Happened To Apple Inc?   http://t.co/FJEX...          0\n",
       "2  Thank u @apple I can now compile all of the pi...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple = pd.read_csv('./apple.csv')\n",
    "apple.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1630 entries, 0 to 1629\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       1630 non-null   object\n",
      " 1   sentiment  1630 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 25.6+ KB\n"
     ]
    }
   ],
   "source": [
    "apple.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = apple['text']\n",
    "y_target = apple['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) CountVectorizer로 피처 벡터화, LogisticRegression으로 모델 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(X_train)\n",
    "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
    "X_test_cnt_vect = cnt_vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8404907975460123"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_cnt_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_cnt_vect)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) TF-IDF로 피처 벡터화, LogisticRegression으로 모델 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8159509202453987"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8016359918200409"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "accuracy_score(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best C: {'C': 10}\n",
      "0.8302658486707567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'C':[0.01, 0.1, 1, 5, 10]}\n",
    "grid_cv_lr = GridSearchCV(lr_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_cv_lr.fit(X_train_tfidf_vect, y_train)\n",
    "print('best C:', grid_cv_lr.best_params_)\n",
    "\n",
    "pred=grid_cv_lr.predict(X_test_tfidf_vect)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
